{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3O1KTgWNxN1"
      },
      "outputs": [],
      "source": [
        "#bruh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qHojWEIx_cRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/[2024-2025]_AN2DL/Homework 1')"
      ],
      "metadata": {
        "id": "zg3Tb69ICITD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a requirements.txt file in which you'll specify the versions of the libraries you want\n",
        "\n",
        "%%writefile requirements.txt\n",
        "tensorflow==2.17.0\n",
        "keras==3.4.1"
      ],
      "metadata": {
        "id": "UM9Ihhq0FuZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "6FhyJilLMWAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "#from tensorflow import keras as tfk\n",
        "import keras as tfk       #notice how I'm importing keras and not tensorflow.keras\n",
        "from keras.layers import Input, Dense, Dropout, Lambda\n",
        "#from tensorflow.keras.layers import Input, Dense, Dropout, Lambda\n",
        "from keras import layers as tfkl\n",
        "\n",
        "\n",
        "print(f\"Tensorflow version (2.17) -> {tf.__version__}\")\n",
        "print(f\"Keras version (3.4.1) -> {tfk.__version__}\")"
      ],
      "metadata": {
        "id": "wDRuUa8hMZW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-cv\n",
        "!pip install tensorflow-probability\n"
      ],
      "metadata": {
        "id": "yXWh8nxPCAyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Tensorflow version (2.17) -> {tf.__version__}\")\n",
        "print(f\"Keras version (3.4.1) -> {tfk.__version__}\")"
      ],
      "metadata": {
        "id": "FlHP6HsJCJLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import models, optimizers, callbacks\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras import mixed_precision\n",
        "import keras_cv  # Keras CV for augmentation layers\n",
        "#import tensorflow_probability as tfp\n",
        "import random"
      ],
      "metadata": {
        "id": "3HwwmDFrBt2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set mixed precision policy\n",
        "#mixed_precision.set_global_policy('mixed_float16')#correct way to do it\n",
        "#mixed_precision.set_global_policy('mixed_float16')\n",
        "mixed_precision.set_global_policy('float32') #augmixdelcazzo\n",
        "\n",
        "print(f\"TensorFlow version -> {tf.__version__}\")\n",
        "print(f\"Keras version -> {tfk.__version__}\")\n",
        "print(f\"Keras CV version -> {keras_cv.__version__}\")"
      ],
      "metadata": {
        "id": "lFMCk2CmCR13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42);"
      ],
      "metadata": {
        "id": "4GTUFbmAPR7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Import + train_val_test_split + balancing the data â™Ÿ"
      ],
      "metadata": {
        "id": "vPaHO8x0jI0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the cleaned dataset\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "file_path = 'training_set_no_outliers.npz'\n",
        "\n",
        "with np.load(file_path) as data:\n",
        "    training_images = data['images']\n",
        "    training_labels = data['labels']\n",
        "\n",
        "#Check\n",
        "print(f\"Shape of images: {training_images.shape}\")\n",
        "print(f\"type of images: {type(training_images)}\")\n",
        "print(f\"shape of labels: {training_labels.shape}\")\n",
        "print(f\"type of labels: {type(training_labels)}\")\n",
        "# Dataframe for labels\n",
        "labels = training_labels.flatten()\n",
        "df_labels = pd.DataFrame(labels, columns=['label'])\n",
        "print(df_labels.head())"
      ],
      "metadata": {
        "id": "JHcYD_-MPNxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train test val split\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Define split sizes\n",
        "test_size = 0.2        # 20% for test\n",
        "validation_size = 0.2  # 20% of the remaining 80% = 16% for validation\n",
        "# Split into (training+validation) and test sets\n",
        "training_labels = training_labels.flatten()\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    training_images,\n",
        "    training_labels,\n",
        "    test_size=test_size,\n",
        "    random_state=42,\n",
        "    stratify=training_labels\n",
        ")\n",
        "# Split into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val,\n",
        "    y_train_val,\n",
        "    test_size=validation_size,\n",
        "    random_state=42,\n",
        "    stratify=y_train_val\n",
        ")\n",
        "print(\"Training Images - Min pixel value:\", np.min(X_train))\n",
        "print(\"Training Images - Max pixel value:\", np.max(X_train))\n",
        "print(\"Test Images - Min pixel value:\", np.min(X_test))\n",
        "print(\"Test Images - Max pixel value:\", np.max(X_test))\n",
        "print(f\"Training set shape: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Validation set shape: {X_val.shape}, {y_val.shape}\")\n",
        "print(f\"Test set shape: {X_test.shape}, {y_test.shape}\")"
      ],
      "metadata": {
        "id": "6YP-JBROyGwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train val split only when you want to remove test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Define split sizes\n",
        "validation_size = 0.1  # 10%\n",
        "# Split into (training+validation) and test sets\n",
        "training_labels = training_labels.flatten()\n",
        "X_train_val, X_val, y_train_val, y_val = train_test_split(\n",
        "    training_images,\n",
        "    training_labels,\n",
        "    test_size=validation_size,\n",
        "    random_state=42,\n",
        "    stratify=training_labels\n",
        ")\n",
        "\n",
        "print(\"Training Images - Min pixel value:\", np.min(X_train))\n",
        "print(\"Training Images - Max pixel value:\", np.max(X_train))\n",
        "print(f\"Training set shape: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Validation set shape: {X_val.shape}, {y_val.shape}\")\n"
      ],
      "metadata": {
        "id": "rM2YBy8ud85x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#OVERSAMPLING\n",
        "import numpy as np\n",
        "class_counts = pd.Series(y_train).value_counts()\n",
        "max_count = class_counts.max()\n",
        "print(f\"Maximum class count: {max_count}\")\n",
        "X_train_oversampled = []\n",
        "y_train_oversampled = []\n",
        "# Iterate through each class to perform oversampling\n",
        "for class_label in class_counts.index:\n",
        "    X_class = X_train[y_train == class_label]\n",
        "    y_class = y_train[y_train == class_label]\n",
        "    samples_needed = max_count - len(X_class)\n",
        "\n",
        "    if samples_needed > 0:\n",
        "        duplicates = samples_needed // len(X_class)\n",
        "        remainder = samples_needed % len(X_class)\n",
        "        for _ in range(duplicates):\n",
        "            X_train_oversampled.append(X_class)\n",
        "            y_train_oversampled.append(y_class)\n",
        "        if remainder > 0:\n",
        "            indices = np.random.choice(len(X_class), size=remainder, replace=True)\n",
        "            X_train_oversampled.append(X_class[indices])\n",
        "            y_train_oversampled.append(y_class[indices])\n",
        "if X_train_oversampled:\n",
        "    X_train_oversampled = np.vstack(X_train_oversampled)\n",
        "    y_train_oversampled = np.hstack(y_train_oversampled)\n",
        "    X_train_balanced = np.vstack((X_train, X_train_oversampled))\n",
        "    y_train_balanced = np.hstack((y_train, y_train_oversampled))\n",
        "else:\n",
        "    X_train_balanced = X_train\n",
        "    y_train_balanced = y_train\n",
        "print(f\"Training set shape after oversampling: {X_train_balanced.shape}, {y_train_balanced.shape}\")"
      ],
      "metadata": {
        "id": "HcyketE70_XE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count classes in training set\n",
        "class_counts = pd.Series(y_train_balanced).value_counts().sort_index()\n",
        "print(\"Class distribution in Training set after oversampling:\")\n",
        "print(class_counts)\n",
        "\n",
        "# Plot for better visualization\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=class_counts.index, y=class_counts.values, palette='viridis')\n",
        "plt.title('Class Distribution in Training Set after Oversampling')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Images')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "04Zq3yFO0f-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_images_per_class(images, labels, classes, num=5):\n",
        "    \"\"\"\n",
        "    Visualizza un numero specificato di immagini per ciascuna classe.\n",
        "\n",
        "    Args:\n",
        "    - images (numpy.ndarray): Array delle immagini.\n",
        "    - labels (numpy.ndarray): Array delle etichette.\n",
        "    - classes (list): Lista delle classi da visualizzare.\n",
        "    - num (int): Numero di immagini per classe.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(15, len(classes) * 3))\n",
        "    for i, cls in enumerate(classes):\n",
        "        cls_indices = np.where(labels == cls)[0]\n",
        "        # Controlla se ci sono abbastanza immagini per la classe\n",
        "        if len(cls_indices) < num:\n",
        "            print(f\"Attenzione: La classe {cls} ha solo {len(cls_indices)} immagini. Verranno visualizzate tutte.\")\n",
        "            selected_indices = cls_indices\n",
        "        else:\n",
        "            selected_indices = np.random.choice(cls_indices, num, replace=False)\n",
        "        for j, idx in enumerate(selected_indices):\n",
        "            plt.subplot(len(classes), num, i*num + j + 1)\n",
        "            plt.imshow(images[idx])\n",
        "            plt.title(f\"Classe: {cls}\")\n",
        "            plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Identificare tutte le classi\n",
        "all_classes = class_counts.index.tolist()\n",
        "print(\"Tutte le classi:\", all_classes)\n",
        "\n",
        "# Visualizzare 5 immagini per ciascuna delle 8 classi\n",
        "plot_images_per_class(training_images, df_labels, all_classes, num=5)"
      ],
      "metadata": {
        "id": "Prb4gAWsMBnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0C9Z4bwqUmcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##AUGMENT AND PREPARE FOR TRAINING + TESTING â›¹"
      ],
      "metadata": {
        "id": "nKO_L9VNnNuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras as tfk  # Standalone Keras\n",
        "from keras.layers import Input, Dense, Dropout, Lambda, GlobalAveragePooling2D\n",
        "from keras import layers as tfkl\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.applications import InceptionResNetV2\n",
        "import keras_cv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ikx3faYeVfiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Tensorflow version (2.17) -> {tf.__version__}\")\n",
        "print(f\"Keras version (3.4.1) -> {tfk.__version__}\")"
      ],
      "metadata": {
        "id": "CXnJFNR9kg0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (224, 224, 3)\n",
        "num_classes = 8  # Adjust based on your dataset\n",
        "batch_size = 512  # You can adjust this based on your hardware"
      ],
      "metadata": {
        "id": "ihqVWXZzViHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_flip_layer = keras_cv.layers.RandomFlip(\"horizontal_and_vertical\")\n",
        "random_rotation_layer = keras_cv.layers.RandomRotation(factor=0.4)\n",
        "random_zoom_layer = keras_cv.layers.RandomZoom(height_factor=0.4, width_factor=0.4)\n",
        "rand_augment_layer = keras_cv.layers.RandAugment(value_range=(0, 1), magnitude=0.4)# Applies random augmentations DESCREASED MAGNITUDE TO 0.3 HOPING IT WONT ET STUCK AT 0.95 (with just 0.3 gets stuck at 0.97), try at 0.2 AND 4 augmentations per image, got 084 instea of more tan 087"
      ],
      "metadata": {
        "id": "wNF3pdDv63jX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_flip_layer = keras_cv.layers.RandomFlip(\"horizontal_and_vertical\")\n",
        "random_rotation_layer= keras_cv.layers.RandomRotation(factor=0.2)\n",
        "random_zoom_layer=keras_cv.layers.RandomZoom(height_factor=0.2, width_factor=0.2)\n",
        "rand_augment_layer = keras_cv.layers.RandAugment(value_range=(0, 1), magnitude=0.2, augmentations_per_image =2)\n",
        "random_noise_layer = tfk.layers.GaussianNoise(stddev=0.1)"
      ],
      "metadata": {
        "id": "_L_6mBjWNnxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.inception_resnet_v2 import preprocess_input"
      ],
      "metadata": {
        "id": "hI08E5y8Bg0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_and_augment(images, labels):\n",
        "    images = tf.image.resize(images, [224, 224])\n",
        "    images = tf.cast(images, tf.float32) / 255.0\n",
        "    images = random_flip_layer(images)\n",
        "    images = random_rotation_layer(images)\n",
        "    images = random_zoom_layer(images)\n",
        "    images = rand_augment_layer(images)\n",
        "\n",
        "    images = random_noise_layer(images)\n",
        "\n",
        "    images = images * 255.0\n",
        "    images = preprocess_input(images)\n",
        "    labels = tf.one_hot(tf.cast(labels, tf.int32), depth=num_classes)\n",
        "    return images, labels\n",
        "\n",
        "def preprocess_val(images, labels):\n",
        "    images = tf.image.resize(images, [224, 224])\n",
        "    images = tf.cast(images, tf.float32)\n",
        "    images = preprocess_input(images)\n",
        "    labels = tf.one_hot(labels, depth=num_classes)\n",
        "    labels = tf.cast(labels, tf.float32)\n",
        "    return images, labels"
      ],
      "metadata": {
        "id": "4l77geSm3oJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_balanced, y_train_balanced))\n",
        "#debugging prints\n",
        "for batch in train_dataset.take(1):\n",
        "    print(f\"Batch image shape: {batch[0].shape}\")\n",
        "    print(f\"Batch label shape: {batch[1].shape}\")\n",
        "    break\n",
        "\n",
        "# Shuffle and batch the dataset\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1000).batch(batch_size)\n",
        "\n",
        "# Apply augmentations on batched data\n",
        "train_dataset = train_dataset.map(\n",
        "    preprocess_and_augment,\n",
        "    num_parallel_calls=tf.data.AUTOTUNE\n",
        ")\n",
        "#debugging prints\n",
        "for batch in train_dataset.take(1):\n",
        "    print(f\"Batch image shape: {batch[0].shape}\")\n",
        "    print(f\"Batch label shape: {batch[1].shape}\")\n",
        "    break\n",
        "\n",
        "# Prefetch for performance\n",
        "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Create TensorFlow Dataset from validation data\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
        "\n",
        "# Apply preprocessing to validation dataset (no augmentations)\n",
        "val_dataset = val_dataset.map(\n",
        "    preprocess_val,\n",
        "    num_parallel_calls=tf.data.AUTOTUNE\n",
        ")\n",
        "\n",
        "# Batch and prefetch validation dataset\n",
        "val_dataset = val_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "#create TensorFlow Dataset from test data\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "\n",
        "# Apply preprocessing to test dataset (no augmentations)\n",
        "test_dataset = test_dataset.map(\n",
        "    preprocess_val,\n",
        "    num_parallel_calls=tf.data.AUTOTUNE\n",
        ")\n",
        "# Batch and prefetch test dataset\n",
        "test_dataset = test_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "rHqoVZ6tWWLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_augmented_images(dataset, rows=3, cols=5):\n",
        "    plt.figure(figsize=(15, 9))\n",
        "    num_images = rows*cols\n",
        "    count = 0\n",
        "    for images, labels in dataset.take(1):  # Take one batch\n",
        "        for i in range(num_images):\n",
        "            if count >= num_images:\n",
        "                break\n",
        "            plt.subplot(rows, cols, count + 1)\n",
        "            img = images[i].numpy()\n",
        "            # Normalize values for visualization if they fall outside [0, 1]\n",
        "            img = (img - np.min(img)) / (np.max(img) - np.min(img))  # Rescale to [0, 1]\n",
        "            img = np.clip(img, 0, 1)  # Clip to ensure valid range for RGB\n",
        "\n",
        "            img = (img * 255).astype(np.uint8)\n",
        "\n",
        "            # Convert one-hot label to class index\n",
        "            label = np.argmax(labels[i].numpy())\n",
        "            plt.imshow(img)\n",
        "            plt.title(f'Label: {label}')\n",
        "            plt.axis('off')\n",
        "            count += 1\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "6ZJBHPV5BO-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display augmented images from the training dataset\n",
        "display_augmented_images(train_dataset, rows=4, cols=5)"
      ],
      "metadata": {
        "id": "KW4y0IAqWuZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MODEL DEFINITION + TRAINING (+ eventual Fine Tuning) âš™"
      ],
      "metadata": {
        "id": "dp-Is1A0ocFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the base model\n",
        "base_model = InceptionResNetV2(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_shape=input_shape\n",
        ")\n",
        "base_model.trainable = False  # Freeze the base model\n",
        "\n",
        "# Define the model architecture\n",
        "inputs = tfkl.Input(shape=input_shape)\n",
        "x = base_model(inputs, training=False)\n",
        "x = tfkl.GlobalAveragePooling2D()(x)\n",
        "# Add Dense and Dropout layers\n",
        "x = tfkl.Dense(256)(x)\n",
        "x = tfkl.BatchNormalization()(x)\n",
        "x = tfkl.Activation('relu')(x)\n",
        "x = tfkl.Dropout(0.5)(x)\n",
        "outputs = tfkl.Dense(num_classes, activation='softmax')(x) # Output layer with softmax activation\n",
        "\n",
        "# Create the complete model\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "# Display the model architecture\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "fcJqID8lWlqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-3),\n",
        "    loss='categorical_crossentropy',  # Suitable for one-hot encoded labels\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "OUKLP3WPWyYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Callbacks\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "#h5 only weights, .keras if whole model\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'best_inceptionresnetv2_model.keras',  # Filename for the best model\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    mode='min'\n",
        ")\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=5,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "# Combine all callbacks\n",
        "callback_list = [early_stop, model_checkpoint, reduce_lr]"
      ],
      "metadata": {
        "id": "JYM-kJbhUg-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Tensorflow version (2.17) -> {tf.__version__}\")\n",
        "print(f\"Keras version (3.4.1) -> {tfk.__version__}\")\n",
        "print(f\"Keras CV version -> {keras_cv.__version__}\")"
      ],
      "metadata": {
        "id": "KSQWgaTkZzY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "epochs = 300  # Adjust this number based on your requirements\n",
        "for batch in train_dataset.take(1): # Take one batch from the dataset\n",
        "    print(f\"Batch image shape: {batch[0].shape}\")  # Print shape of images in the batch\n",
        "    print(f\"Batch label shape: {batch[1].shape}\")  # Print shape of labels in the batch\n",
        "    break # Stop after the first batch\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_dataset,\n",
        "    callbacks=callback_list,\n",
        ")"
      ],
      "metadata": {
        "id": "AsJ7C3xDW0S-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy and loss\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Accuracy plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "# Loss plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8CMDARMUVLRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##In case of loading a pretrained model: import + fine tuning\n"
      ],
      "metadata": {
        "id": "P8XPdmH7pO07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD\n",
        "best_model = tfk.models.load_model('best_inceptionresnetv2_model_087.keras')\n",
        "print(f\"Number of layers in the base model: {len(best_model.layers)}\")"
      ],
      "metadata": {
        "id": "_C3GS6B0VNEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Layers in best_model:\")\n",
        "for idx, layer in enumerate(best_model.layers):\n",
        "    print(f\"{idx}: {layer.name}\")\n",
        "best_model.summary()"
      ],
      "metadata": {
        "id": "jOt2tPvtRJF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = best_model.get_layer('inception_resnet_v2')  # Replace with the actual name\n",
        "print(f\"Number of layers in the base model: {len(base_model.layers)}\")"
      ],
      "metadata": {
        "id": "1vrLFqW1WSLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Callbacks\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "#h5 only weights, .keras if whole model\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'best_inceptionresnetv2_model.keras',  # Filename for the best model\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    mode='min'\n",
        ")\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=5,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "best_model.summary()\n",
        "# Combine all callbacks\n",
        "callback_list = [early_stop, model_checkpoint, reduce_lr]"
      ],
      "metadata": {
        "id": "8PVJ6U5xNKdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "#FINE TUUNE\n",
        "base_model.trainable = True\n",
        "\n",
        "# Let's say we unfreeze the last 50 layers, by freezing everything but he last 50\n",
        "for layer in base_model.layers[:-250]:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "optimizer = SGD(learning_rate=1e-3, momentum=0.9, nesterov=True)\n",
        "best_model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "# Fine-tuning with adjusted `initial_epoch`\n",
        "fine_tune_epochs = 30  # Adjust as needed\n",
        "total_epochs = fine_tune_epochs\n",
        "history_fine = best_model.fit(\n",
        "    train_dataset,\n",
        "    epochs=total_epochs,\n",
        "    initial_epoch=0,\n",
        "    validation_data=val_dataset,\n",
        "    callbacks=callback_list,\n",
        ")\n"
      ],
      "metadata": {
        "id": "3mW0tEFZmUcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy and loss\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Accuracy plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_fine.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history_fine.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "# Loss plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_fine.history['loss'], label='Train Loss')\n",
        "plt.plot(history_fine.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xj-uyfhksxqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#when submitting, use this\n",
        "best_model.optimizer = None\n",
        "best_model.summary()\n",
        "best_model.save('best_inceptionresnetv2_model__087_for_testing.keras', include_optimizer=False)\n"
      ],
      "metadata": {
        "id": "ReeMdeFDP1zI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###if more needed"
      ],
      "metadata": {
        "id": "uXmjRyYlpy5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally, re-freeze layers if you had unfrozen them earlier\n",
        "base_model.trainable = True\n",
        "\n",
        "for layer in base_model.layers[:-150]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Recompile the original model\n",
        "best_model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "p0wMn5Ve_Weh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune_epochs = 30  # Adjust as needed\n",
        "last_epoch = history_fine.epoch[-1]\n",
        "total_epochs = last_epoch + fine_tune_epochs + 1  # To continue from the next epoch\n",
        "\n",
        "history_fine = best_model.fit(\n",
        "    train_dataset,\n",
        "    epochs=total_epochs,\n",
        "    initial_epoch=last_epoch + 1,  # Start from the next epoch after initial training\n",
        "    validation_data=val_dataset,\n",
        "    callbacks=callback_list,\n",
        ")"
      ],
      "metadata": {
        "id": "lH0Gnz80_JzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy and loss\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Accuracy plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_fine.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history_fine.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "# Loss plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_fine.history['loss'], label='Train Loss')\n",
        "plt.plot(history_fine.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LB62Via75-fE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###per class fine tuning, not sure if it works correctly (substitute output layer, train with subset of classes, then put the old output layer back)"
      ],
      "metadata": {
        "id": "wLKnzUfch1qo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the weights of the original output layer\n",
        "original_output_layer = best_model.get_layer('dense_6')  # Replace 'dense' with your actual output layer name\n",
        "original_weights = original_output_layer.get_weights()\n"
      ],
      "metadata": {
        "id": "WfUs93Kjh1cZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the existing output layer\n",
        "x = best_model.layers[-2].output  # Assuming the second last layer is before output\n",
        "new_output = Dense(4, activation='softmax', name='new_output')(x)\n",
        "model_fine_tune = Model(inputs=best_model.input, outputs=new_output)\n",
        "\n",
        "# Compile the fine-tuned model as before\n",
        "model_fine_tune.compile(\n",
        "    optimizer=Adam(learning_rate=1e-5),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "sH-heS8Th7A7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes_of_interest = [0, 3, 5, 6]"
      ],
      "metadata": {
        "id": "EmcjBmyfh7Dm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create boolean masks for classes of interest\n",
        "train_mask = np.isin(y_train_balanced, classes_of_interest)\n",
        "val_mask = np.isin(y_val, classes_of_interest)\n",
        "\n",
        "# Filter the training and validation data\n",
        "X_train_fine = X_train_balanced[train_mask]\n",
        "y_train_fine = y_train_balanced[train_mask]\n",
        "\n",
        "\n",
        "X_val_fine = X_val[val_mask]\n",
        "y_val_fine = y_val[val_mask]"
      ],
      "metadata": {
        "id": "a9dE82H2jM3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Filtered training samples: {X_train_fine.shape[0]}\")\n",
        "print(f\"Filtered validation samples: {X_val_fine.shape[0]}\")"
      ],
      "metadata": {
        "id": "UarjsrWSjM59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a mapping from original labels to new labels\n",
        "label_mapping = {original_label: new_label for new_label, original_label in enumerate(classes_of_interest)}\n",
        "\n",
        "# Function to remap labels\n",
        "def remap_labels(labels, mapping):\n",
        "    return np.array([mapping[label] for label in labels])\n",
        "\n",
        "# Remap the labels in training and validation data\n",
        "y_train_fine_mapped = remap_labels(y_train_fine, label_mapping)\n",
        "y_val_fine_mapped = remap_labels(y_val_fine, label_mapping)\n",
        "\n",
        "# Verify the mapping\n",
        "print(\"Original to New Label Mapping:\")\n",
        "for orig, new in label_mapping.items():\n",
        "    print(f\"Original Label {orig} -> New Label {new}\")\n"
      ],
      "metadata": {
        "id": "fVphWPshjM82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing function for training data\n",
        "def preprocess_train3(images, labels):\n",
        "   # Resize images\n",
        "    images = tf.image.resize(images, [224, 224])\n",
        "\n",
        "    # Normalize pixel values to [0, 1]\n",
        "    images = tf.cast(images, tf.float32) / 255.0\n",
        "\n",
        "    # Apply augmentations\n",
        "    images = random_flip_layer(images)\n",
        "    images = random_rotation_layer(images)\n",
        "    images = random_zoom_layer(images)\n",
        "    #images = grid_mask_layer(images)\n",
        "    images = rand_augment_layer(images)\n",
        "\n",
        "    # Rescale images back to [0, 255]\n",
        "    images = images * 255.0\n",
        "    # Apply InceptionResNetV2 preprocessing\n",
        "    #expecting 0, 255\n",
        "    images = preprocess_input(images)  # Scales to [-1, 1]\n",
        "\n",
        "    # One-hot encode labels\n",
        "    labels = tf.one_hot(tf.cast(labels, tf.int32), depth=4)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "# Preprocessing function for validation data\n",
        "def preprocess_val3(images, labels):\n",
        "    images = tf.image.resize(images, [224, 224])\n",
        "    # Cast images to float32\n",
        "    images = tf.cast(images, tf.float32)\n",
        "    # Normalize and preprocess\n",
        "    images = preprocess_input(images)\n",
        "\n",
        "    labels = tf.one_hot(labels, depth=4)\n",
        "    labels = tf.cast(labels, tf.float32)\n",
        "    return images, labels\n",
        "\n",
        "# Create TensorFlow Dataset from filtered training data\n",
        "train_dataset_fine = tf.data.Dataset.from_tensor_slices((X_train_fine, y_train_fine_mapped))\n",
        "\n",
        "# Shuffle, batch, and apply preprocessing\n",
        "train_dataset_fine = train_dataset_fine.shuffle(buffer_size=1000).batch(batch_size)\n",
        "train_dataset_fine = train_dataset_fine.map(\n",
        "    preprocess_train3,\n",
        "    num_parallel_calls=tf.data.AUTOTUNE\n",
        ")\n",
        "train_dataset_fine = train_dataset_fine.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Create TensorFlow Dataset from filtered validation data\n",
        "val_dataset_fine = tf.data.Dataset.from_tensor_slices((X_val_fine, y_val_fine_mapped))\n",
        "\n",
        "# Batch and apply preprocessing\n",
        "val_dataset_fine = val_dataset_fine.batch(batch_size).map(\n",
        "    preprocess_val3, num_parallel_calls=tf.data.AUTOTUNE\n",
        ")\n",
        "val_dataset_fine = val_dataset_fine.prefetch(tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "D2J7qr6GjM_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_layers = best_model.layers[:-1]\n",
        "x = model_layers[-1].output\n",
        "\n",
        "# Add new Dense layer with 4 classes\n",
        "new_output = Dense(4, activation='softmax', name='new_output')(x)\n",
        "\n",
        "# Create the new fine-tuned model\n",
        "model_fine_tune = Model(inputs=best_model.input, outputs=new_output)\n",
        "\n",
        "# Display the new model architecture\n",
        "model_fine_tune.summary()"
      ],
      "metadata": {
        "id": "0Qv-As6tjzmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all layers in the base model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Optionally, unfreeze the last N layers for fine-tuning\n",
        "unfreeze_layers = 50  # Adjust based on experimentation and computational resources\n",
        "\n",
        "for layer in base_model.layers[-unfreeze_layers:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "print(f\"Number of trainable layers in base_model after unfreezing last {unfreeze_layers} layers: \"\n",
        "      f\"{sum([layer.trainable for layer in base_model.layers])}/{len(base_model.layers)}\")\n"
      ],
      "metadata": {
        "id": "xJrNLtD0lxyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the fine-tuned model\n",
        "fine_tune_lr = 1e-5  # Lower learning rate for fine-tuning\n",
        "\n",
        "model_fine_tune.compile(\n",
        "    optimizer=Adam(learning_rate=fine_tune_lr),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "8OHOvl2Nlx7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training parameters\n",
        "fine_tune_epochs = 10  # Adjust based on your needs\n",
        "total_epochs = fine_tune_epochs  # If this is the initial fine-tuning phase\n",
        "\n",
        "# Fine-tune the model\n",
        "history_fine = model_fine_tune.fit(\n",
        "    train_dataset_fine,\n",
        "    epochs=total_epochs,\n",
        "    validation_data=val_dataset_fine,\n",
        "    callbacks=callback_list\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "2ElOQirFl--t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the fine-tuned output layer\n",
        "model_fine_tune = Model(inputs=best_model.input, outputs=model_fine_tune.layers[-2].output)\n",
        "\n",
        "# Add the original output layer back\n",
        "original_output_layer_readded = Dense(8, activation='softmax', name='dense')(model_fine_tune.output)  # Replace 'dense' and 8 with your actual settings\n",
        "best_model = Model(inputs=model_fine_tune.input, outputs=original_output_layer_readded)\n",
        "\n",
        "# Load the original output layer weights\n",
        "best_model.get_layer('dense').set_weights(original_weights)\n",
        "\n",
        "\n",
        "\n",
        "# Now, best_model is back to its original state\n"
      ],
      "metadata": {
        "id": "GwjPHbSCh7G2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.summary()"
      ],
      "metadata": {
        "id": "wF1bR5DNAM27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TESTING âœŠ"
      ],
      "metadata": {
        "id": "t7qqf3pstLYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Tensorflow version (2.17) -> {tf.__version__}\")\n",
        "print(f\"Keras version (3.4.1) -> {tfk.__version__}\")"
      ],
      "metadata": {
        "id": "Y75ymJNykiUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Get true labels and predictions\n",
        "y_true = np.concatenate([y for x, y in test_dataset], axis=0)\n",
        "y_true = np.argmax(y_true, axis=1)\n",
        "\n",
        "y_pred_probs = best_model.predict(test_dataset)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "class_names = ['class_0', 'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6', 'class_7']\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MwNIeed46aPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "report = classification_report(y_true, y_pred, target_names=class_names)\n",
        "print(report)"
      ],
      "metadata": {
        "id": "sIM37QRn6d-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get indices of misclassified and correctly classified samples\n",
        "misclassified_indices = np.where(y_pred != y_true)[0]\n",
        "correctly_classified_indices = np.where(y_pred == y_true)[0]\n",
        "\n",
        "# Number of samples to display\n",
        "num_samples = 5\n",
        "\n",
        "# Display samples\n",
        "fig, axes = plt.subplots(num_samples, 2, figsize=(10, 2 * num_samples))\n",
        "\n",
        "for i in range(num_samples):\n",
        "    # Misclassified samples\n",
        "    if i < len(misclassified_indices):\n",
        "        idx = misclassified_indices[i]\n",
        "        image = X_test[idx]\n",
        "        true_label = y_true[idx]\n",
        "        predicted_label = y_pred[idx]\n",
        "        axes[i, 0].imshow(image.astype('uint8'))\n",
        "        axes[i, 0].set_title(f'Misclassified\\nTrue: {class_names[true_label]}, Pred: {class_names[predicted_label]}')\n",
        "        axes[i, 0].axis('off')\n",
        "    else:\n",
        "        axes[i, 0].axis('off')\n",
        "\n",
        "    # Correctly classified samples\n",
        "    if i < len(correctly_classified_indices):\n",
        "        idx = correctly_classified_indices[i]\n",
        "        image = X_test[idx]\n",
        "        true_label = y_true[idx]\n",
        "        predicted_label = y_pred[idx]\n",
        "        axes[i, 1].imshow(image.astype('uint8'))\n",
        "        axes[i, 1].set_title(f'Correctly Classified\\nTrue: {class_names[true_label]}')\n",
        "        axes[i, 1].axis('off')\n",
        "    else:\n",
        "        axes[i, 1].axis('off')\n",
        "\n",
        "# Adjust layout\n",
        "fig.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Kc0VAKmh6f9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probabilities = y_pred_probs"
      ],
      "metadata": {
        "id": "bR5P_8CH6ocS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np  # Explicitly import numpy\n",
        "\n",
        "# Index of the image to display probabilities for\n",
        "# Use randint to get a random integer within the range\n",
        "image_index = np.random.randint(0, len(train_dataset))\n",
        "\n",
        "# Extract probabilities and display them\n",
        "probs = probabilities[image_index]\n",
        "for class_idx, prob in enumerate(probs):\n",
        "    print(f'Class {class_idx} ({class_names[class_idx]}): {prob*100:.2f}%')\n",
        "\n",
        "# Display the image alongside the probabilities\n",
        "image = X_test[image_index]  # Assuming X_test contains the test images\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(image.astype('uint8'))\n",
        "plt.axis('off')\n",
        "plt.title(f\"True Label: {class_names[y_true[image_index]]}\\nPredicted: {class_names[np.argmax(probs)]}\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "o-5T3e8c6qnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "plt.bar(range(num_classes), probs)\n",
        "plt.xticks(range(num_classes), class_names, rotation=45)\n",
        "plt.ylabel('Probability')\n",
        "plt.title('Predicted Probabilities')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mDByhm8Q6s4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##interpretability stuff"
      ],
      "metadata": {
        "id": "-PxqKxfptzSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Tensorflow version (2.17) -> {tf.__version__}\")\n",
        "print(f\"Keras version (3.4.1) -> {tfk.__version__}\")"
      ],
      "metadata": {
        "id": "OLl7UV2pkjyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Grad CAM ? to try"
      ],
      "metadata": {
        "id": "Cm1gpD6Nt-7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#needs last CONVOLUTIONAL LAYER!\n",
        "base_model.summary()"
      ],
      "metadata": {
        "id": "maSGiyfNnFpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Define a function to recursively find a layer by name\n",
        "def find_layer(model, layer_name):\n",
        "    \"\"\"\n",
        "    Recursively search for a layer by name in a nested model.\n",
        "\n",
        "    Args:\n",
        "        model (tf.keras.Model): The model to search within.\n",
        "        layer_name (str): The name of the layer to find.\n",
        "\n",
        "    Returns:\n",
        "        tf.keras.layers.Layer: The found layer.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If the layer is not found.\n",
        "    \"\"\"\n",
        "    if model.name == layer_name:\n",
        "        return model\n",
        "    for layer in model.layers:\n",
        "        if layer.name == layer_name:\n",
        "            return layer\n",
        "        elif isinstance(layer, Model):\n",
        "            try:\n",
        "                return find_layer(layer, layer_name)\n",
        "            except ValueError:\n",
        "                continue\n",
        "    raise ValueError(f\"Layer '{layer_name}' not found in the model.\")\n",
        "\n",
        "# Define a function to get the last Conv2D layer\n",
        "def get_last_conv_layer(model):\n",
        "    \"\"\"\n",
        "    Retrieves the last Conv2D layer in the model.\n",
        "\n",
        "    Args:\n",
        "        model (tf.keras.Model): The model to search within.\n",
        "\n",
        "    Returns:\n",
        "        tf.keras.layers.Layer: The last Conv2D layer.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If no Conv2D layer is found.\n",
        "    \"\"\"\n",
        "    # Iterate through the layers in reverse order\n",
        "    for layer in reversed(model.layers):\n",
        "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "            return layer\n",
        "        elif isinstance(layer, Model):\n",
        "            try:\n",
        "                return get_last_conv_layer(layer)\n",
        "            except ValueError:\n",
        "                continue\n",
        "    raise ValueError(\"No Conv2D layer found in the model.\")\n",
        "\n",
        "# Define the Grad-CAM heatmap generation function with debugging\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer, pred_index=None):\n",
        "    \"\"\"\n",
        "    Generates a Grad-CAM heatmap for a given image and model.\n",
        "\n",
        "    Args:\n",
        "        img_array (np.array): Preprocessed image array with shape (1, 224, 224, 3).\n",
        "        model (tf.keras.Model): The model to analyze.\n",
        "        last_conv_layer (tf.keras.layers.Layer): The last convolutional layer.\n",
        "        pred_index (int, optional): Index of the class to generate heatmap for. Defaults to the top predicted class.\n",
        "\n",
        "    Returns:\n",
        "        np.array: Heatmap array.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Create a model that maps the input image to the activations of the last conv layer and the output predictions\n",
        "        grad_model = Model([model.inputs], [last_conv_layer.output, model.output])\n",
        "        print(\"Grad model created successfully.\")\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass without specifying 'training' parameter\n",
        "            conv_outputs, predictions = grad_model(img_array)\n",
        "            print(\"Forward pass successful.\")\n",
        "            if pred_index is None:\n",
        "                pred_index = tf.argmax(predictions[0])\n",
        "                print(f\"No pred_index provided, using top predicted class: {pred_index}\")\n",
        "            else:\n",
        "                print(f\"Using provided pred_index: {pred_index}\")\n",
        "            loss = predictions[:, pred_index]\n",
        "            print(f\"Loss shape: {loss.shape}\")\n",
        "\n",
        "        # Compute gradients of the loss with respect to the last conv layer output\n",
        "        grads = tape.gradient(loss, conv_outputs)\n",
        "        print(f\"Gradients computed: {grads.shape}\")\n",
        "\n",
        "        # Compute the guided gradients\n",
        "        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2)).numpy()\n",
        "        print(f\"Pooled grads shape: {pooled_grads.shape}\")\n",
        "\n",
        "        # Multiply each channel in the feature map array by \"how important this channel is\" with regard to the top predicted class\n",
        "        conv_outputs = conv_outputs[0].numpy()  # Shape: (H, W, C)\n",
        "        print(f\"Conv outputs shape: {conv_outputs.shape}\")\n",
        "        for i in range(pooled_grads.shape[0]):\n",
        "            conv_outputs[:, :, i] *= pooled_grads[i]\n",
        "        print(\"Applied pooled gradients to conv outputs.\")\n",
        "\n",
        "        # Compute the heatmap by averaging the feature map channels\n",
        "        heatmap = np.mean(conv_outputs, axis=-1)\n",
        "        print(f\"Heatmap shape after mean: {heatmap.shape}\")\n",
        "\n",
        "        # Apply ReLU to the heatmap to keep only positive activations\n",
        "        heatmap = np.maximum(heatmap, 0)\n",
        "        print(\"Applied ReLU to heatmap.\")\n",
        "\n",
        "        # Normalize the heatmap\n",
        "        max_heat = np.max(heatmap)\n",
        "        if max_heat == 0:\n",
        "            max_heat = 1e-10  # To prevent division by zero\n",
        "        heatmap /= max_heat\n",
        "        print(\"Normalized heatmap.\")\n",
        "\n",
        "        return heatmap\n",
        "    except Exception as e:\n",
        "        print(\"Exception in make_gradcam_heatmap:\")\n",
        "        print(e)\n",
        "        raise\n",
        "\n",
        "# Define the Grad-CAM display function\n",
        "def display_gradcam(image, heatmap, class_names, y_true, y_pred, alpha=0.4):\n",
        "    \"\"\"\n",
        "    Superimposes the Grad-CAM heatmap on the original image and displays it.\n",
        "\n",
        "    Args:\n",
        "        image (np.array): Original image array with shape (224, 224, 3).\n",
        "        heatmap (np.array): Grad-CAM heatmap array.\n",
        "        class_names (list): List of class names.\n",
        "        y_true (int): True class index.\n",
        "        y_pred (int): Predicted class index.\n",
        "        alpha (float, optional): Transparency factor for heatmap. Defaults to 0.4.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Resize heatmap to match image size\n",
        "        heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))\n",
        "        print(\"Resized heatmap to match image size.\")\n",
        "\n",
        "        # Convert heatmap to RGB (apply color map)\n",
        "        heatmap = np.uint8(255 * heatmap)\n",
        "        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "        print(\"Applied color map to heatmap.\")\n",
        "\n",
        "        # Ensure image is in uint8\n",
        "        if image.dtype != 'uint8':\n",
        "            image = image.astype('uint8')\n",
        "            print(\"Converted image to uint8.\")\n",
        "\n",
        "        # Superimpose the heatmap on the original image\n",
        "        superimposed_img = cv2.addWeighted(image, alpha, heatmap, 1 - alpha, 0)\n",
        "        print(\"Superimposed heatmap on image.\")\n",
        "\n",
        "        # Display the image\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        plt.imshow(superimposed_img)\n",
        "        plt.axis('off')\n",
        "        plt.title(f\"Grad-CAM\\nTrue: {class_names[y_true]}, Pred: {class_names[y_pred]}\")\n",
        "        plt.show()\n",
        "    except Exception as e:\n",
        "        print(\"Exception in display_gradcam:\")\n",
        "        print(e)\n",
        "        raise\n",
        "\n",
        "# ----------------- Main Code Execution -----------------\n",
        "\n",
        "# Define your class names\n",
        "# Replace this with your actual class names\n",
        "class_names = ['class_0', 'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6', 'class_7']\n",
        "\n",
        "# Load your trained model\n",
        "# Replace 'best_inceptionresnetv2_model.keras' with your actual model file\n",
        "best_model = tf.keras.models.load_model('best_inceptionresnetv2_model.keras')\n",
        "print(\"Model loaded successfully.\")\n",
        "\n",
        "# Verify model input shape\n",
        "print(f\"Model input shape: {best_model.input_shape}\")\n",
        "\n",
        "# Find the last Conv2D layer automatically\n",
        "try:\n",
        "    last_conv_layer = get_last_conv_layer(best_model)\n",
        "    print(f\"Last convolutional layer: {last_conv_layer.name}\")\n",
        "except ValueError as e:\n",
        "    print(e)\n",
        "    # Optionally, list available layers for debugging\n",
        "    print(\"Available layers in the model:\")\n",
        "    for layer in best_model.layers:\n",
        "        print(layer.name, layer.__class__.__name__)\n",
        "    raise\n",
        "\n",
        "# Check the shape of X_test\n",
        "# Ensure that X_test is defined and loaded before this point\n",
        "# Replace 'X_test' and 'y_test' with your actual test data variables\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "\n",
        "# Select a random image from the test set\n",
        "image_index = random.randint(0, len(X_test) - 1)\n",
        "image = X_test[image_index]\n",
        "true_label = y_test[image_index]\n",
        "\n",
        "# Prepare the image for the model\n",
        "img = np.expand_dims(image, axis=0)  # Shape: (1, 96, 96, 3)\n",
        "\n",
        "# Resize the image to match the model's expected input size\n",
        "img_resized = tf.image.resize(img, [224, 224])  # Resize to 224x224\n",
        "\n",
        "# Preprocess the image\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\n",
        "img_processed = preprocess_input(img_resized)  # Ensure consistency with training preprocessing\n",
        "\n",
        "# Verify image shape\n",
        "print(f\"Processed image shape ver: {img_processed.shape}\")  # Should be (1, 224, 224, 3)\n",
        "\n",
        "# Test standard prediction to ensure the model is working\n",
        "try:\n",
        "    predictions = best_model.predict(img_processed)\n",
        "    predicted_class = np.argmax(predictions[0])\n",
        "    print(f\"Predicted class index: {predicted_class}\")\n",
        "except Exception as e:\n",
        "    print(\"Error during model prediction:\")\n",
        "    print(e)\n",
        "    raise\n",
        "\n",
        "# Generate Grad-CAM heatmap\n",
        "try:\n",
        "    # Use 'predicted_class' directly\n",
        "    heatmap = make_gradcam_heatmap(img_processed, best_model, last_conv_layer, pred_index=predicted_class)\n",
        "    print(f\"Heatmap shape: {heatmap.shape}\")  # Should match resized image dimensions (224, 224)\n",
        "    print(f\"Heatmap max value: {np.max(heatmap)}\")  # Should be 1.0 after normalization\n",
        "except Exception as e:\n",
        "    print(\"Error during Grad-CAM heatmap generation:\")\n",
        "    print(e)\n",
        "    raise\n",
        "\n",
        "# Display Grad-CAM\n",
        "try:\n",
        "    display_gradcam(image, heatmap, class_names, true_label, predicted_class)\n",
        "except Exception as e:\n",
        "    print(\"Error during Grad-CAM display:\")\n",
        "    print(e)\n",
        "    raise\n"
      ],
      "metadata": {
        "id": "cab8f7vyoIVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Select an image to visualize Grad-CAM\n",
        "image_index = np.random.randint(0, len(X_test))\n",
        "image = X_test[image_index]\n",
        "true_label = y_true[image_index]\n",
        "predicted_label = y_pred[image_index]\n",
        "\n",
        "# Expand dimensions to match model input\n",
        "img = np.expand_dims(image, axis=0)\n",
        "\n",
        "# Resize to 299x299 as expected by InceptionResNetV2\n",
        "#img_resized = tf.image.resize(img, [299, 299])\n",
        "\n",
        "# Preprocess the image\n",
        "img_processed = preprocess_val(image, labels)\n",
        "\n",
        "# Create a model that maps the input image to the activations of the last conv layer and the model's output\n",
        "grad_model = Model(\n",
        "    inputs=base_model.inputs,\n",
        "    outputs=[base_model.get_layer(\"conv_7b\").output, best_model.output]\n",
        ")\n",
        "img_processed = preprocess_input(tf.image.resize(img, [224, 224]))\n",
        "# Record operations for automatic differentiation\n",
        "with tf.GradientTape() as tape:\n",
        "    conv_outputs, predictions = grad_model(img_processed)\n",
        "    loss = predictions[:, predicted_label]\n",
        "\n",
        "# Compute gradients of the loss with respect to the last conv layer output\n",
        "grads = tape.gradient(loss, conv_outputs)\n",
        "\n",
        "# Compute the guided gradients\n",
        "pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2)).numpy()\n",
        "\n",
        "# Multiply each channel in the feature map array by \"how important this channel is\" with regard to the top predicted class\n",
        "conv_outputs = conv_outputs[0].numpy()  # Shape: (H, W, C)\n",
        "for i in range(pooled_grads.shape[0]):\n",
        "    conv_outputs[:, :, i] *= pooled_grads[i]\n",
        "\n",
        "# Compute the heatmap by averaging the feature map channels\n",
        "heatmap = np.mean(conv_outputs, axis=-1)\n",
        "\n",
        "# Apply ReLU to the heatmap to keep only positive activations\n",
        "heatmap = np.maximum(heatmap, 0)\n",
        "\n",
        "# Normalize the heatmap\n",
        "heatmap /= np.max(heatmap) if np.max(heatmap) != 0 else 1\n",
        "\n",
        "# Resize heatmap to match the original image size\n",
        "heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))\n",
        "\n",
        "# Convert heatmap to RGB (apply color map)\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "\n",
        "# Superimpose the heatmap on the original image\n",
        "superimposed_img = cv2.addWeighted(image.astype('uint8'), 0.6, heatmap, 0.4, 0)\n",
        "\n",
        "# Display the image\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(superimposed_img)\n",
        "plt.axis('off')\n",
        "plt.title(f\"Grad-CAM\\nTrue: {class_names[true_label]}, Pred: {class_names[predicted_label]}\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NJL_2iJZUPR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = X_test[image_index]\n",
        "img = np.expand_dims(img, axis=0)\n"
      ],
      "metadata": {
        "id": "l9j5V7BM6vOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the image as per your model's requirements\n",
        "img_processed = preprocess_input(tf.image.resize(img, [224, 224]))\n"
      ],
      "metadata": {
        "id": "rpUK82tq61mI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grad_model = tfk.models.Model(\n",
        "    [best_model.inputs],\n",
        "    [best_model.get_layer('dense_6').output, best_model.output]\n",
        ")\n"
      ],
      "metadata": {
        "id": "0awoYCDa63HM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.GradientTape() as tape:\n",
        "    conv_outputs, predictions = grad_model(img_processed)\n",
        "    predictions_tensor = predictions[0]\n",
        "    loss = predictions_tensor[:, np.argmax(predictions_tensor[0])]\n",
        "\n",
        "grads = tape.gradient(loss, conv_outputs)\n"
      ],
      "metadata": {
        "id": "8gLTc8q764kY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pooled_grads = tf.reduce_mean(grads, axis=(0))\n",
        "conv_outputs = conv_outputs[0]\n",
        "heatmap = tf.reshape(conv_outputs, (1, -1)) @ pooled_grads[..., tf.newaxis]\n",
        "\n",
        "heatmap = tf.squeeze(heatmap)\n",
        "heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n"
      ],
      "metadata": {
        "id": "ubazZ0zg66I-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "img = img[0].astype('uint8')\n",
        "heatmap = heatmap.numpy()\n",
        "if heatmap.ndim == 0:\n",
        "    print(\"0 dim\")\n",
        "    heatmap = heatmap.reshape(1, 1)\n",
        "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "superimposed_img = cv2.addWeighted(img, 0.6, heatmap, 0.4, 0)\n",
        "plt.imshow(superimposed_img)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xeOjMwOZ67dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###others"
      ],
      "metadata": {
        "id": "082o81D9uLZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " import shap\n",
        "\n",
        "  # Create an explainer\n",
        "  explainer = shap.GradientExplainer(model, X_train[:100])\n",
        "\n",
        "  # Compute SHAP values\n",
        "  shap_values = explainer.shap_values(X_val[:10])\n",
        "\n",
        "  # Plot SHAP values for the first image\n",
        "  shap.image_plot(shap_values, X_val[:10])"
      ],
      "metadata": {
        "id": "n9fbyjBC2YhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from lime import lime_image\n",
        "  from skimage.segmentation import mark_boundaries\n",
        "\n",
        "  explainer = lime_image.LimeImageExplainer()\n",
        "  explanation = explainer.explain_instance(X_val[0], model.predict, top_labels=5, hide_color=0, num_samples=1000)\n",
        "  temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=10, hide_rest=False)\n",
        "  plt.imshow(mark_boundaries(temp / 255.0, mask))\n",
        "  plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "uSSNT_Qz2c1i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}